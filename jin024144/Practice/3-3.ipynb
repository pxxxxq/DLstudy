{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    length   height   width\n",
      "0      8.4     2.11    1.41\n",
      "1     13.7     3.53    2.00\n",
      "2     15.0     3.82    2.43\n",
      "3     16.2     4.59    2.63\n",
      "4     17.4     4.59    2.94\n",
      "5     18.0     5.22    3.32\n",
      "6     18.7     5.20    3.12\n",
      "7     19.0     5.64    3.05\n",
      "8     19.6     5.14    3.04\n",
      "9     20.0     5.08    2.77\n",
      "10    21.0     5.69    3.56\n",
      "11    21.0     5.92    3.31\n",
      "12    21.0     5.69    3.67\n",
      "13    21.3     6.38    3.53\n",
      "14    22.0     6.11    3.41\n",
      "15    22.0     5.64    3.52\n",
      "16    22.0     6.11    3.52\n",
      "17    22.0     5.88    3.52\n",
      "18    22.0     5.52    4.00\n",
      "19    22.5     5.86    3.62\n",
      "20    22.5     6.79    3.62\n",
      "21    22.7     5.95    3.63\n",
      "22    23.0     5.22    3.63\n",
      "23    23.5     6.28    3.72\n",
      "24    24.0     7.29    3.72\n",
      "25    24.0     6.38    3.82\n",
      "26    24.6     6.73    4.17\n",
      "27    25.0     6.44    3.68\n",
      "28    25.6     6.56    4.24\n",
      "29    26.5     7.17    4.14\n",
      "30    27.3     8.32    5.14\n",
      "31    27.5     7.17    4.34\n",
      "32    27.5     7.05    4.34\n",
      "33    27.5     7.28    4.57\n",
      "34    28.0     7.82    4.20\n",
      "35    28.7     7.59    4.64\n",
      "36    30.0     7.62    4.77\n",
      "37    32.8    10.03    6.02\n",
      "38    34.5    10.26    6.39\n",
      "39    35.0    11.49    7.80\n",
      "40    36.5    10.88    6.86\n",
      "41    36.0    10.61    6.74\n",
      "42    37.0    10.84    6.26\n",
      "43    37.0    10.57    6.37\n",
      "44    39.0    11.14    7.49\n",
      "45    39.0    11.14    6.00\n",
      "46    39.0    12.43    7.35\n",
      "47    40.0    11.93    7.11\n",
      "48    40.0    11.73    7.22\n",
      "49    40.0    12.38    7.46\n",
      "50    40.0    11.14    6.63\n",
      "51    42.0    12.80    6.87\n",
      "52    43.0    11.93    7.28\n",
      "53    43.0    12.51    7.42\n",
      "54    43.5    12.60    8.14\n",
      "55    44.0    12.49    7.60\n",
      "[[ 8.4   2.11  1.41]\n",
      " [13.7   3.53  2.  ]\n",
      " [15.    3.82  2.43]\n",
      " [16.2   4.59  2.63]\n",
      " [17.4   4.59  2.94]\n",
      " [18.    5.22  3.32]\n",
      " [18.7   5.2   3.12]\n",
      " [19.    5.64  3.05]\n",
      " [19.6   5.14  3.04]\n",
      " [20.    5.08  2.77]\n",
      " [21.    5.69  3.56]\n",
      " [21.    5.92  3.31]\n",
      " [21.    5.69  3.67]\n",
      " [21.3   6.38  3.53]\n",
      " [22.    6.11  3.41]\n",
      " [22.    5.64  3.52]\n",
      " [22.    6.11  3.52]\n",
      " [22.    5.88  3.52]\n",
      " [22.    5.52  4.  ]\n",
      " [22.5   5.86  3.62]\n",
      " [22.5   6.79  3.62]\n",
      " [22.7   5.95  3.63]\n",
      " [23.    5.22  3.63]\n",
      " [23.5   6.28  3.72]\n",
      " [24.    7.29  3.72]\n",
      " [24.    6.38  3.82]\n",
      " [24.6   6.73  4.17]\n",
      " [25.    6.44  3.68]\n",
      " [25.6   6.56  4.24]\n",
      " [26.5   7.17  4.14]\n",
      " [27.3   8.32  5.14]\n",
      " [27.5   7.17  4.34]\n",
      " [27.5   7.05  4.34]\n",
      " [27.5   7.28  4.57]\n",
      " [28.    7.82  4.2 ]\n",
      " [28.7   7.59  4.64]\n",
      " [30.    7.62  4.77]\n",
      " [32.8  10.03  6.02]\n",
      " [34.5  10.26  6.39]\n",
      " [35.   11.49  7.8 ]\n",
      " [36.5  10.88  6.86]\n",
      " [36.   10.61  6.74]\n",
      " [37.   10.84  6.26]\n",
      " [37.   10.57  6.37]\n",
      " [39.   11.14  7.49]\n",
      " [39.   11.14  6.  ]\n",
      " [39.   12.43  7.35]\n",
      " [40.   11.93  7.11]\n",
      " [40.   11.73  7.22]\n",
      " [40.   12.38  7.46]\n",
      " [40.   11.14  6.63]\n",
      " [42.   12.8   6.87]\n",
      " [43.   11.93  7.28]\n",
      " [43.   12.51  7.42]\n",
      " [43.5  12.6   8.14]\n",
      " [44.   12.49  7.6 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('https://bit.ly/perch_csv_data')\n",
    "print(df)\n",
    "perch_full = df.to_numpy()\n",
    "print(perch_full) #판다스는 넘파이와 달리 인터넷에서 바로 데이터를 불러올 수 있다는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
    "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
    "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
    "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
    "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
    "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
    "       1000.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(perch_full,perch_weight,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 9)\n",
      "[[  19.6       5.14      3.04    384.16    100.744    59.584    26.4196\n",
      "    15.6256    9.2416]\n",
      " [  22.        5.88      3.52    484.      129.36     77.44     34.5744\n",
      "    20.6976   12.3904]\n",
      " [  18.7       5.2       3.12    349.69     97.24     58.344    27.04\n",
      "    16.224     9.7344]\n",
      " [  17.4       4.59      2.94    302.76     79.866    51.156    21.0681\n",
      "    13.4946    8.6436]\n",
      " [  36.       10.61      6.74   1296.      381.96    242.64    112.5721\n",
      "    71.5114   45.4276]\n",
      " [  25.        6.44      3.68    625.      161.       92.       41.4736\n",
      "    23.6992   13.5424]\n",
      " [  40.       11.93      7.11   1600.      477.2     284.4     142.3249\n",
      "    84.8223   50.5521]\n",
      " [  39.       12.43      7.35   1521.      484.77    286.65    154.5049\n",
      "    91.3605   54.0225]\n",
      " [  43.       11.93      7.28   1849.      512.99    313.04    142.3249\n",
      "    86.8504   52.9984]\n",
      " [  22.        5.64      3.52    484.      124.08     77.44     31.8096\n",
      "    19.8528   12.3904]\n",
      " [  20.        5.08      2.77    400.      101.6      55.4      25.8064\n",
      "    14.0716    7.6729]\n",
      " [  22.        6.11      3.52    484.      134.42     77.44     37.3321\n",
      "    21.5072   12.3904]\n",
      " [  24.        7.29      3.72    576.      174.96     89.28     53.1441\n",
      "    27.1188   13.8384]\n",
      " [  27.5       7.17      4.34    756.25    197.175   119.35     51.4089\n",
      "    31.1178   18.8356]\n",
      " [  43.       12.51      7.42   1849.      537.93    319.06    156.5001\n",
      "    92.8242   55.0564]\n",
      " [  40.       11.73      7.22   1600.      469.2     288.8     137.5929\n",
      "    84.6906   52.1284]\n",
      " [  24.        6.38      3.82    576.      153.12     91.68     40.7044\n",
      "    24.3716   14.5924]\n",
      " [  21.        5.92      3.31    441.      124.32     69.51     35.0464\n",
      "    19.5952   10.9561]\n",
      " [  27.5       7.05      4.34    756.25    193.875   119.35     49.7025\n",
      "    30.597    18.8356]\n",
      " [  40.       12.38      7.46   1600.      495.2     298.4     153.2644\n",
      "    92.3548   55.6516]\n",
      " [  32.8      10.03      6.02   1075.84    328.984   197.456   100.6009\n",
      "    60.3806   36.2404]\n",
      " [  26.5       7.17      4.14    702.25    190.005   109.71     51.4089\n",
      "    29.6838   17.1396]\n",
      " [  36.5      10.88      6.86   1332.25    397.12    250.39    118.3744\n",
      "    74.6368   47.0596]\n",
      " [  13.7       3.53      2.      187.69     48.361    27.4      12.4609\n",
      "     7.06      4.    ]\n",
      " [  22.7       5.95      3.63    515.29    135.065    82.401    35.4025\n",
      "    21.5985   13.1769]\n",
      " [  15.        3.82      2.43    225.       57.3      36.45     14.5924\n",
      "     9.2826    5.9049]\n",
      " [  37.       10.57      6.37   1369.      391.09    235.69    111.7249\n",
      "    67.3309   40.5769]\n",
      " [  35.       11.49      7.8    1225.      402.15    273.      132.0201\n",
      "    89.622    60.84  ]\n",
      " [  28.7       7.59      4.64    823.69    217.833   133.168    57.6081\n",
      "    35.2176   21.5296]\n",
      " [  23.5       6.28      3.72    552.25    147.58     87.42     39.4384\n",
      "    23.3616   13.8384]\n",
      " [  39.       11.14      6.     1521.      434.46    234.      124.0996\n",
      "    66.84     36.    ]\n",
      " [  21.        5.69      3.56    441.      119.49     74.76     32.3761\n",
      "    20.2564   12.6736]\n",
      " [  23.        5.22      3.63    529.      120.06     83.49     27.2484\n",
      "    18.9486   13.1769]\n",
      " [  22.        5.52      4.      484.      121.44     88.       30.4704\n",
      "    22.08     16.    ]\n",
      " [  44.       12.49      7.6    1936.      549.56    334.4     156.0001\n",
      "    94.924    57.76  ]\n",
      " [  22.5       6.79      3.62    506.25    152.775    81.45     46.1041\n",
      "    24.5798   13.1044]\n",
      " [  19.        5.64      3.05    361.      107.16     57.95     31.8096\n",
      "    17.202     9.3025]\n",
      " [  37.       10.84      6.26   1369.      401.08    231.62    117.5056\n",
      "    67.8584   39.1876]\n",
      " [  22.        6.11      3.41    484.      134.42     75.02     37.3321\n",
      "    20.8351   11.6281]\n",
      " [  25.6       6.56      4.24    655.36    167.936   108.544    43.0336\n",
      "    27.8144   17.9776]\n",
      " [  42.       12.8       6.87   1764.      537.6     288.54    163.84\n",
      "    87.936    47.1969]\n",
      " [  34.5      10.26      6.39   1190.25    353.97    220.455   105.2676\n",
      "    65.5614   40.8321]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures #새로운\n",
    "\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "poly.fit(train_input)\n",
    "train_poly = poly.transform(train_input)\n",
    "print(train_poly.shape)\n",
    "print(train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2',\n",
       "       'x2^2'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.get_feature_names_out() #get_feature_names메서드는 9개의 특성이 각각 어떤 입력의 조합으로 만들어졌는지 알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이제 테스트 세트 변환하기\n",
    "\n",
    "test_poly = poly.transform(test_input) #fit()이 호출되지 않더라도, fit()을 이미 호출한 학습 데이터(train_input)와 같은 차원의 입력(test_input)이 주어지면 바로 transform()이 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903183436982124\n",
      "0.9714559911594124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_poly,train_target)\n",
    "print(lr.score(train_poly,train_target))\n",
    "\n",
    "print(lr.score(test_poly,test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다행히 과소적합은 해결되었음\n",
    "특성을 더 많이 추가하면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 55)\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
    "poly.fit(train_input)\n",
    "train_poly = poly.transform(train_input)\n",
    "test_poly=poly.transform(test_input)\n",
    "print(train_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성이 너무많은데... 누가 봐도 과대적합 발생할것같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999997242\n",
      "-144.40564485442695\n"
     ]
    }
   ],
   "source": [
    "lr.fit(train_poly,train_target)\n",
    "print(lr.score(train_poly,train_target))\n",
    "print(lr.score(test_poly,test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "너무 과대적합됨.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
